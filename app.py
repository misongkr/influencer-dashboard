import re
from pathlib import Path
from datetime import datetime
import numpy as np
import pandas as pd
import streamlit as st
import altair as alt

import subprocess

# -----------------------------
# Config
# -----------------------------
st.set_page_config(
    page_title="ì¸í”Œë£¨ì–¸ì„œ ì „ëµ ëŒ€ì‹œë³´ë“œ",
    layout="wide"
)

def check_password():
    if "authed" not in st.session_state:
        st.session_state.authed = False

    if not st.session_state.authed:
        st.sidebar.markdown("### ğŸ”’ Access")
        pwd = st.sidebar.text_input("ë¹„ë°€ë²ˆí˜¸", type="password")

        if pwd == st.secrets["APP_PASSWORD"]:
            st.session_state.authed = True
            st.rerun()
        else:
            st.sidebar.caption("ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")
            st.stop()

check_password()


PLATFORM_COLORS = {
    "ì¹˜ì§€ì§": "#A8E05F",  # ì—°ë‘
    "SOOP": "#8FD3F4",   # í•˜ëŠ˜
}

# ê¸°ì—¬ íƒ€ì… ì»¬ëŸ¬(í”Œë«í¼ ì»¬ëŸ¬ì™€ ê²¹ì¹˜ì§€ ì•Šê²Œ)
TYPE_BADGE = {
    "ì‹œê°„í˜•": {"bg": "#C4B5FD", "fg": "#312E81"},   # í¼í”Œ
    "íŒŒì›Œí˜•": {"bg": "#FCA5A5", "fg": "#7F1D1D"},   # ë ˆë“œ
    "ë°¸ëŸ°ìŠ¤í˜•": {"bg": "#D1D5DB", "fg": "#111827"}, # ê·¸ë ˆì´
}

# íŒŒì¼ëª…ì—ì„œ YYYYMMDD ì¶”ì¶œ
DATE_RE = re.compile(r"(20\d{6})")



# -----------------------------
# Utils
# -----------------------------
def parse_snapshot_date_from_name(name: str):
    m = DATE_RE.search(name)
    if not m:
        return None
    try:
        return datetime.strptime(m.group(1), "%Y%m%d").date()
    except ValueError:
        return None


def parse_period_from_filename(name: str):
    """
    ë°˜í™˜:
    - ("weekly", date)   â†’ YYYYMMDD
    - ("monthly", date)  â†’ YYYYMM (í•´ë‹¹ ì›” 1ì¼ë¡œ normalize)
    - (None, None)
    """
    stem = Path(name).stem

    # 1) ì£¼ê°„: YYYYMMDD (8ìë¦¬) ë¨¼ì €
    m = re.search(r"(20\d{6}\d{2})", stem)  # YYYYMMDD
    if m:
        token = m.group(1)
        try:
            return "weekly", datetime.strptime(token, "%Y%m%d").date()
        except ValueError:
            pass

    # 2) ì›”ê°„: YYYYMM (6ìë¦¬)
    m = re.search(r"(20\d{4}\d{2})(?!\d)", stem)  # YYYYMM (ë’¤ì— ìˆ«ì ë” ë¶™ìœ¼ë©´ ì œì™¸)
    if m:
        token = m.group(1)
        try:
            return "monthly", datetime.strptime(token, "%Y%m").date()
        except ValueError:
            pass

    return None, None



def to_number(x):
    if pd.isna(x):
        return np.nan
    if isinstance(x, (int, float, np.integer, np.floating)):
        return float(x)
    s = str(x).strip().replace(",", "")
    if s == "" or s.lower() in ("nan", "none", "-"):
        return np.nan
    try:
        return float(s)
    except ValueError:
        return np.nan


def pct_change(curr, prev):
    if prev is None or pd.isna(prev) or prev == 0:
        return None
    return (curr - prev) / prev * 100.0


def fmt_pct(x):
    if x is None or pd.isna(x):
        return "N/A"
    sign = "+" if x >= 0 else ""
    return f"{sign}{x:.0f}%"

def kpi_with_wow(curr, prev, decimals=0):
    """
    decimals=0: ì •ìˆ˜ ë°˜ì˜¬ë¦¼ í‘œì‹œ
    decimals=1: ì†Œìˆ˜ì  1ìë¦¬ í‘œì‹œ(ê°€ì¤‘ í‰ê·  ì‹œì²­ììš©)
    ë°˜í™˜ ì˜ˆ) 25,664 (<span ...>(â†‘6%)</span>)
    """
    if curr is None or pd.isna(curr):
        return "N/A"

    # ê°’ í¬ë§·
    if decimals == 0:
        curr_txt = f"{float(curr):,.0f}"
    else:
        curr_txt = f"{float(curr):,.{decimals}f}"

    # ì „ì£¼ ê°’ ì—†ìœ¼ë©´
    if prev is None or pd.isna(prev) or prev == 0:
        return f"{curr_txt} (N/A)"

    wow = pct_change(curr, prev)
    if wow is None or pd.isna(wow):
        return f"{curr_txt} (N/A)"

    if wow > 0:
        wow_txt = f"<span style='color:#DC2626;'>(â†‘{wow:.0f}%)</span>"
    elif wow < 0:
        wow_txt = f"<span style='color:#2563EB;'>(â†“{abs(wow):.0f}%)</span>"
    else:
        wow_txt = "(0%)"

    return f"{curr_txt} {wow_txt}"



def ensure_columns(df, required, df_name="df"):
    missing = [c for c in required if c not in df.columns]
    if missing:
        raise ValueError(f"[{df_name}] missing columns: {missing}")


def to_monday(dt_series: pd.Series) -> pd.Series:
    d = pd.to_datetime(dt_series, errors="coerce")
    # Monday=0
    return (d - pd.to_timedelta(d.dt.weekday, unit="D")).dt.normalize()


# -----------------------------
# Loaders (ìš´ì˜ ë£° ë°˜ì˜)
# -----------------------------
@st.cache_data(show_spinner=False)
def load_latest_prev_streamer_softcon_and_cat(data_dir: str):
    data_path = Path(data_dir)
    if not data_path.exists():
        return None

    def read_csv(fp: Path):
        df = pd.read_csv(fp, encoding="utf-8-sig")
        df.columns = [str(c).strip() for c in df.columns]
        return df

    # -------------------------------------------------
    # filename íŒŒì„œ: YYYYMMDD_HHMMSS / YYYYMMDDHHMMSS / YYYYMMDD
    # -------------------------------------------------
    def parse_dt_from_stem(stem: str):
        """
        ìš°ì„ ìˆœìœ„:
        1) YYYYMMDD[_-]HHMMSS  (ì˜ˆ: 20260216_101535)
        2) YYYYMMDDHHMMSS      (ì˜ˆ: 20260216101535)
        3) YYYYMMDD            (ì˜ˆ: 20260216)
        """
        s = stem

        m = re.search(r"(20\d{6})[_-](\d{6})", s)
        if m:
            try:
                return datetime.strptime(m.group(1) + m.group(2), "%Y%m%d%H%M%S")
            except ValueError:
                pass

        m = re.search(r"(20\d{6})(\d{6})", s)
        if m:
            try:
                return datetime.strptime(m.group(1) + m.group(2), "%Y%m%d%H%M%S")
            except ValueError:
                pass

        m = re.search(r"(20\d{6})", s)
        if m:
            try:
                return datetime.strptime(m.group(1), "%Y%m%d")
            except ValueError:
                pass

        return None

    def pick_latest_file(pattern: str):
        files = list(data_path.glob(pattern))
        if not files:
            return None

        pairs = []
        for f in files:
            dt = parse_dt_from_stem(f.stem)
            if dt is not None:
                pairs.append((dt, f))

        # íŒŒì¼ëª…ì—ì„œ ë‚ ì§œ íŒŒì‹± ì•ˆ ë˜ë©´ ìˆ˜ì •ì‹œê°„(mtime)ìœ¼ë¡œ fallback
        if not pairs:
            return max(files, key=lambda p: p.stat().st_mtime)

        pairs.sort(key=lambda x: x[0])
        return pairs[-1][1]

    def pick_latest_prev_files(pattern: str):
        """
        patternì— í•´ë‹¹í•˜ëŠ” íŒŒì¼ë“¤ ì¤‘ ìµœì‹ /ì „ì£¼(ë°”ë¡œ ì´ì „) íŒŒì¼ì„ ë°˜í™˜
        return: (latest_dt, latest_fp, prev_dt, prev_fp)
        """
        files = list(data_path.glob(pattern))
        if not files:
            return (None, None, None, None)

        pairs = []
        for f in files:
            dt = parse_dt_from_stem(f.stem)
            if dt is not None:
                pairs.append((dt, f))

        if not pairs:
            # dt íŒŒì‹± ì‹¤íŒ¨ -> mtime ê¸°ë°˜
            files = sorted(files, key=lambda p: p.stat().st_mtime)
            latest_fp = files[-1]
            prev_fp = files[-2] if len(files) >= 2 else None
            return (None, latest_fp, None, prev_fp)

        pairs.sort(key=lambda x: x[0])
        latest_dt, latest_fp = pairs[-1]
        prev_dt, prev_fp = (pairs[-2] if len(pairs) >= 2 else (None, None))
        return (latest_dt, latest_fp, prev_dt, prev_fp)

    # -------------------------------------------------
    # (ì„ íƒ) ì›”ê°„/ì£¼ê°„ êµ¬ë¶„: ê¸°ì¡´ ë¡œì§ ìœ ì§€
    # ì›”ê°„ì€ YYYYMMë§Œ ìˆëŠ” íŒŒì¼ë„ ìˆìœ¼ë‹ˆ ê¸°ì¡´ parse_period_from_filename ì‚¬ìš©
    # -------------------------------------------------
    def period_files(pattern: str, kind: str):
        files = list(data_path.glob(pattern))
        pairs = []
        for f in files:
            k, d = parse_period_from_filename(f.name)
            if k == kind and d is not None:
                # ì›”ê°„ì€ dateë§Œ ìˆìœ¼ë‹ˆ (date, file)ë¡œ ì •ë ¬
                pairs.append((d, f))
        pairs.sort(key=lambda x: x[0])
        return pairs

    # âœ… ì£¼ê°„ ìŠ¤íŠ¸ë¦¬ë¨¸ (ë‚ ì§œ+ì‹œê°„ê¹Œì§€ ê³ ë ¤)
    sr_latest_dt, sr_latest_fp, sr_prev_dt, sr_prev_fp = pick_latest_prev_files("ìŠ¤íŠ¸ë¦¬ë¨¸_ë­í‚¹*.csv")

    # âœ… ì›”ê°„ ìŠ¤íŠ¸ë¦¬ë¨¸ (íŒŒì¼ëª…ì´ YYYYMMë§Œ ìˆëŠ” ê²½ìš°)
    sr_m_pairs = period_files("ìŠ¤íŠ¸ë¦¬ë¨¸_ë­í‚¹*.csv", "monthly")
    sr_m_latest_date, sr_m_latest_fp = (sr_m_pairs[-1] if len(sr_m_pairs) >= 1 else (None, None))
    sr_m_prev_date, sr_m_prev_fp = (sr_m_pairs[-2] if len(sr_m_pairs) >= 2 else (None, None))

    # âœ… ì†Œí”„íŠ¸ì½˜(ì£¼ê°„) (ë‚ ì§œ+ì‹œê°„ê¹Œì§€ ê³ ë ¤)
    sc_latest_dt, sc_latest_fp, sc_prev_dt, sc_prev_fp = pick_latest_prev_files("ì†Œí”„íŠ¸ì½˜_ë­í‚¹*.csv")

    # âœ… ì¹´í…Œê³ ë¦¬ í†µê³„: ê°€ì¥ ìµœê·¼ ìƒì„±ë³¸(íŒŒì¼ëª… ë‚ ì§œ+ì‹œê°„) ì„ íƒ (í•µì‹¬ ìˆ˜ì •)
    cat_fp = pick_latest_file("ì¹´í…Œê³ ë¦¬_í”Œë«í¼ë³„_í†µê³„*.csv")

    # ìœ íš¨ì„± ì²´í¬
    if (sr_latest_fp is None) or (cat_fp is None):
        return None

    # streamer_latest_date / prev_dateëŠ” ê¸°ì¡´ íƒ€ì…(date) ê¸°ëŒ€í•˜ë‹ˆê¹Œ dateë¡œ normalize
    streamer_latest_date = sr_latest_dt.date() if isinstance(sr_latest_dt, datetime) else None
    streamer_prev_date = sr_prev_dt.date() if isinstance(sr_prev_dt, datetime) else None

    softcon_latest_date = sc_latest_dt.date() if isinstance(sc_latest_dt, datetime) else None
    softcon_prev_date = sc_prev_dt.date() if isinstance(sc_prev_dt, datetime) else None

    return {
        "streamer_latest_date": streamer_latest_date,
        "streamer_prev_date": streamer_prev_date,
        "streamer_latest": read_csv(sr_latest_fp),
        "streamer_prev": read_csv(sr_prev_fp) if sr_prev_fp else None,

        "streamer_monthly_latest_date": sr_m_latest_date,
        "streamer_monthly_prev_date": sr_m_prev_date,
        "streamer_monthly_latest": read_csv(sr_m_latest_fp) if sr_m_latest_fp else None,
        "streamer_monthly_prev": read_csv(sr_m_prev_fp) if sr_m_prev_fp else None,

        "softcon_latest_date": softcon_latest_date,
        "softcon_prev_date": softcon_prev_date,
        "softcon_latest": read_csv(sc_latest_fp) if sc_latest_fp else None,
        "softcon_prev": read_csv(sc_prev_fp) if sc_prev_fp else None,

        "cat_current": read_csv(cat_fp),
        "cat_filename": cat_fp.name,
    }


def split_curr_prev_weeks_from_cat_stats(cat_stats_raw: pd.DataFrame):
    """
    ì¹´í…Œê³ ë¦¬_í”Œë«í¼ë³„_í†µê³„(ëˆ„ì  1íŒŒì¼)ì—ì„œ
    ìµœì‹  ì£¼(ì›”ìš”ì¼) / ì „ì£¼ ì£¼(ì›”ìš”ì¼) ë°ì´í„°í”„ë ˆì„ì„ ë°˜í™˜
    """
    cs = normalize_category_platform_stats(cat_stats_raw)
    cs = cs.dropna(subset=["ë‚ ì§œ"])
    cs["ì£¼ì°¨(ì›”)"] = to_monday(cs["ë‚ ì§œ"])

    weeks = sorted(cs["ì£¼ì°¨(ì›”)"].dropna().unique())
    curr_week = weeks[-1] if len(weeks) >= 1 else None
    prev_week = weeks[-2] if len(weeks) >= 2 else None

    cs_curr = cs[cs["ì£¼ì°¨(ì›”)"] == curr_week].copy() if curr_week is not None else cs.iloc[0:0].copy()
    cs_prev = cs[cs["ì£¼ì°¨(ì›”)"] == prev_week].copy() if prev_week is not None else cs.iloc[0:0].copy()
    return curr_week, prev_week, cs_curr, cs_prev


# -----------------------------
# Normalizers
# -----------------------------
def normalize_streamer_rank(df: pd.DataFrame) -> pd.DataFrame:
    rename_map = {
        "ìµœê³  ì‹œì²­ì": "ìµœê³ ì‹œì²­ì",
        "í‰ê·  ì‹œì²­ì": "í‰ê· ì‹œì²­ì",
        "ë°©ì†¡ ì‹œê°„": "ë°©ì†¡ì‹œê°„",
    }
    df = df.rename(columns=rename_map).copy()

    required = ["í”Œë«í¼", "ìŠ¤íŠ¸ë¦¬ë¨¸", "ë°©ì†¡ì‹œê°„", "í‰ê· ì‹œì²­ì", "ë·°ì–´ì‹­"]
    ensure_columns(df, required, "streamer_rank")

    for c in ["ë°©ì†¡ì‹œê°„", "ìµœê³ ì‹œì²­ì", "í‰ê· ì‹œì²­ì", "ë·°ì–´ì‹­"]:
        if c in df.columns:
            df[c] = df[c].map(to_number)

    df["í”Œë«í¼"] = df["í”Œë«í¼"].astype(str).str.strip()
    df["ìŠ¤íŠ¸ë¦¬ë¨¸"] = df["ìŠ¤íŠ¸ë¦¬ë¨¸"].astype(str).str.strip()
    df = df.dropna(subset=["í”Œë«í¼", "ìŠ¤íŠ¸ë¦¬ë¨¸"])
    return df


def normalize_category_platform_stats(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]

    col_candidates = {
        "platform": ["í”Œë«í¼", "platform"],
        "date": ["ë‚ ì§œ", "ì¼ì", "date"],
        "stream_time": ["ë°©ì†¡ì‹œê°„", "ë°©ì†¡ ì‹œê°„"],
        "avg_viewers": ["ì‹œì²­ììˆ˜ í‰ê· ", "í‰ê·  ì‹œì²­ì", "í‰ê· ì‹œì²­ì"],
        "avg_chat": ["6ë¶„ë‹¹ ì±„íŒ…ìˆ˜ í‰ê· ", "í‰ê·  ì±„íŒ…ìˆ˜", "6ë¶„ í‰ê· "],
        "viewership": ["ë·°ì–´ì‹­", "ëˆ„ì  ë·°ì–´ì‹­"],
    }

    def pick(col_list):
        for c in col_list:
            if c in df.columns:
                return c
        return None

    platform_col = pick(col_candidates["platform"])
    date_col = pick(col_candidates["date"])
    stream_time_col = pick(col_candidates["stream_time"])
    avg_viewers_col = pick(col_candidates["avg_viewers"])
    avg_chat_col = pick(col_candidates["avg_chat"])
    viewership_col = pick(col_candidates["viewership"])

    out = pd.DataFrame()

    # platformì€ í•„ìˆ˜
    if platform_col is None:
        out["í”Œë«í¼"] = np.nan
    else:
        out["í”Œë«í¼"] = df[platform_col].astype(str).str.strip()

    # -------------------------
    # âœ… ë‚ ì§œ íŒŒì‹± (í•µì‹¬)
    # -------------------------
    if date_col is None:
        out["ë‚ ì§œ"] = pd.NaT
    else:
        raw = df[date_col]

        # 1) ìˆ«ìí˜•(ì—‘ì…€ ì‹œë¦¬ì–¼/yyyymmdd) ê°€ëŠ¥ì„±
        if pd.api.types.is_numeric_dtype(raw):
            s = raw.copy()

            # excel serialë¡œ ë³´ì´ëŠ” ê°’ (ëŒ€ëµ 30000~80000)
            mask_excel = s.between(30000, 80000, inclusive="both")
            out_date = pd.Series([pd.NaT] * len(s), index=df.index)

            if mask_excel.any():
                out_date.loc[mask_excel] = pd.to_datetime(
                    s.loc[mask_excel],
                    unit="D",
                    origin="1899-12-30",
                    errors="coerce"
                )

            # ë‚˜ë¨¸ì§€ëŠ” yyyymmdd ì‹œë„
            rest = ~mask_excel
            if rest.any():
                out_date.loc[rest] = pd.to_datetime(
                    s.loc[rest].astype("Int64").astype(str),
                    format="%Y%m%d",
                    errors="coerce"
                )

            out["ë‚ ì§œ"] = out_date

        else:
            raw_date = raw.astype(str).str.strip()

            # ê´„í˜¸/ìš”ì¼ ì œê±°
            raw_date = raw_date.str.replace(r"\s*\([^)]*\)\s*", "", regex=True)

            # í•œê¸€/ê¸°íƒ€ í…ìŠ¤íŠ¸ ì œê±°
            raw_date = raw_date.str.replace(r"[ê°€-í£]+", "", regex=True).str.strip()

            # êµ¬ë¶„ì í†µì¼
            raw_date = raw_date.str.replace(".", "-", regex=False).str.replace("/", "-", regex=False)

            # ê³µë°± ìˆìœ¼ë©´ ì• í† í°ë§Œ
            raw_date2 = raw_date.str.split().str[0]

            # 1ì°¨: YYYY-MM-DD
            out_dt = pd.to_datetime(raw_date2, format="%Y-%m-%d", errors="coerce")

            # 2ì°¨: YYYYMMDD
            mask = out_dt.isna()
            if mask.any():
                out_dt.loc[mask] = pd.to_datetime(raw_date2.loc[mask], format="%Y%m%d", errors="coerce")

            out["ë‚ ì§œ"] = out_dt

    # -------------------------
    # ë‚˜ë¨¸ì§€ ìˆ˜ì¹˜ ì»¬ëŸ¼
    # -------------------------
    out["ë°©ì†¡ì‹œê°„"] = df[stream_time_col].map(to_number) if stream_time_col else np.nan
    out["í‰ê· ì‹œì²­ì"] = df[avg_viewers_col].map(to_number) if avg_viewers_col else np.nan
    out["í‰ê· ì±„íŒ…"] = df[avg_chat_col].map(to_number) if avg_chat_col else np.nan
    out["ë·°ì–´ì‹­"] = df[viewership_col].map(to_number) if viewership_col else np.nan

    out = out.dropna(subset=["í”Œë«í¼"])
    return out


# -----------------------------
# Metrics
# -----------------------------
def compute_overview_metrics(streamer_rank: pd.DataFrame, cat_stats_week: pd.DataFrame):
    """
    cat_stats_week: ë°˜ë“œì‹œ 'í•´ë‹¹ ì£¼ì°¨' ë°ì´í„°ë§Œ ë“¤ì–´ì˜¤ë„ë¡ (ë©”ì¸ì—ì„œ í•„í„°ë§)
    """
    sr = normalize_streamer_rank(streamer_rank)

    cs = cat_stats_week.copy()
    # cat_stats_weekëŠ” split í•¨ìˆ˜ì—ì„œ ì´ë¯¸ normalize_category_platform_stats() ê²°ê³¼ì—¬ì•¼ í•˜ì§€ë§Œ,
    # í˜¹ì‹œ rawê°€ ë“¤ì–´ì˜¤ë©´ ëŒ€ë¹„
    if ("í‰ê· ì‹œì²­ì" not in cs.columns) or ("ë°©ì†¡ì‹œê°„" not in cs.columns) or ("í”Œë«í¼" not in cs.columns):
        cs = normalize_category_platform_stats(cs)

    # --- Totals (ìŠ¤íŠ¸ë¦¬ë¨¸ ë­í‚¹ ê¸°ë°˜) ---
    total_stream_time = sr["ë°©ì†¡ì‹œê°„"].sum(skipna=True)
    total_viewership = sr["ë·°ì–´ì‹­"].sum(skipna=True)

    # ê°€ì¤‘ í‰ê·  ì‹œì²­ì(ë·°ì–´ì‹­/ë°©ì†¡ì‹œê°„) = ì§€ê¸ˆê¹Œì§€ 'í‰ê·  ì‹œì²­ì=8'ì˜ ì •ì²´
    weighted_avg_viewers = (total_viewership / total_stream_time) if total_stream_time and total_stream_time > 0 else np.nan

    # --- í‰ê·  ì‹œì²­ì(ì¹´í…Œê³ ë¦¬ í†µê³„ ê¸°ë°˜, ACV) ---
    # ë‘ í”Œë«í¼ì„ "í•©ì‚°"í•˜ëŠ” ê°œë…ìœ¼ë¡œ: ë°©ì†¡ì‹œê°„ìœ¼ë¡œ ê°€ì¤‘í‰ê· 
    cs_v = cs.dropna(subset=["í‰ê· ì‹œì²­ì", "ë°©ì†¡ì‹œê°„"]).copy()
    cs_v = cs_v[(cs_v["í‰ê· ì‹œì²­ì"] > 0) & (cs_v["ë°©ì†¡ì‹œê°„"] > 0)]

    if len(cs_v) > 0:
        cat_avg_viewers = (cs_v["í‰ê· ì‹œì²­ì"] * cs_v["ë°©ì†¡ì‹œê°„"]).sum() / cs_v["ë°©ì†¡ì‹œê°„"].sum()
    else:
        cat_avg_viewers = np.nan

    # --- Platform comparison (ìŠ¤íŠ¸ë¦¬ë¨¸ ë­í‚¹ ê¸°ë°˜) ---
    platform_df = (
        sr.groupby("í”Œë«í¼", as_index=False)
          .agg(ë°©ì†¡ì‹œê°„=("ë°©ì†¡ì‹œê°„", "sum"), ë·°ì–´ì‹­=("ë·°ì–´ì‹­", "sum"))
    )
    platform_df["í‰ê· ì‹œì²­ì"] = platform_df.apply(
        lambda r: (r["ë·°ì–´ì‹­"] / r["ë°©ì†¡ì‹œê°„"]) if r["ë°©ì†¡ì‹œê°„"] and r["ë°©ì†¡ì‹œê°„"] > 0 else np.nan,
        axis=1
    )

    # --- Top streamers (ìŠ¤íŠ¸ë¦¬ë¨¸ ë­í‚¹ ê¸°ë°˜) ---
    top_df = (
        sr.groupby(["í”Œë«í¼", "ìŠ¤íŠ¸ë¦¬ë¨¸"], as_index=False)
          .agg(
              ë°©ì†¡ì‹œê°„=("ë°©ì†¡ì‹œê°„", "sum"),
              í‰ê· ì‹œì²­ì=("í‰ê· ì‹œì²­ì", "mean"),
              ë·°ì–´ì‹­=("ë·°ì–´ì‹­", "sum"),
          )
    )

    top_df["ê¸°ì—¬ìœ¨"] = top_df["ë·°ì–´ì‹­"] / total_viewership if total_viewership and total_viewership > 0 else np.nan

    # ê¸°ì—¬ íƒ€ì… ë¶„ë¥˜(ìŠ¤ëƒ…ìƒ· ë‚´ ìƒëŒ€ ë­í¬)
    top_df["ë°©ì†¡ì‹œê°„_rank"] = top_df["ë°©ì†¡ì‹œê°„"].rank(pct=True, ascending=False)
    top_df["í‰ê· ì‹œì²­ì_rank"] = top_df["í‰ê· ì‹œì²­ì"].rank(pct=True, ascending=False)

    def classify(row):
        # ìƒìœ„ ê¸°ì¤€: top 25% (<=0.25), í•˜ìœ„ ê¸°ì¤€: bottom 50% (>0.5)
        if row["ë°©ì†¡ì‹œê°„_rank"] <= 0.25 and row["í‰ê· ì‹œì²­ì_rank"] > 0.5:
            return "ì‹œê°„í˜•"
        elif row["ë°©ì†¡ì‹œê°„_rank"] > 0.5 and row["í‰ê· ì‹œì²­ì_rank"] <= 0.25:
            return "íŒŒì›Œí˜•"
        else:
            return "ë°¸ëŸ°ìŠ¤í˜•"

    top_df["ê¸°ì—¬ íƒ€ì…"] = top_df.apply(classify, axis=1)

    # Top10: ë·°ì–´ì‹­ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ
    top10 = top_df.sort_values("ë·°ì–´ì‹­", ascending=False).head(10).copy()

    extra = {
        "top_streamer_name": top10.iloc[0]["ìŠ¤íŠ¸ë¦¬ë¨¸"] if len(top10) else None,
        "top_streamer_share": top10.iloc[0]["ê¸°ì—¬ìœ¨"] if len(top10) else None,
    }

    # --- KPI (í‘œì‹œìš©) ---
    kpis = {
        "ì´ ë·°ì–´ì‹­": total_viewership,
        "í‰ê·  ì‹œì²­ì(ì¹´í…Œê³ ë¦¬)": cat_avg_viewers,                 # ì‚¬ëŒë“¤ì´ ê¸°ëŒ€í•˜ëŠ” í‰ê· ì‹œì²­ì(ACV)
        "ì´ ë°©ì†¡ì‹œê°„": total_stream_time,
        "ê°€ì¤‘ í‰ê·  ì‹œì²­ì(ë·°ì–´ì‹­/ì‹œê°„)": weighted_avg_viewers,     # ê¸°ì¡´ 8.xëŠ” ì—¬ê¸°ë¡œ
    }

    return kpis, platform_df, top10, top_df, extra



def platform_wow_increment(curr_pf: pd.DataFrame, prev_pf: pd.DataFrame) -> pd.DataFrame:
    a = curr_pf[["í”Œë«í¼", "ë·°ì–´ì‹­"]].rename(columns={"ë·°ì–´ì‹­": "curr_viewership"})
    b = prev_pf[["í”Œë«í¼", "ë·°ì–´ì‹­"]].rename(columns={"ë·°ì–´ì‹­": "prev_viewership"})
    m = a.merge(b, on="í”Œë«í¼", how="outer").fillna(0)

    m["delta_viewership"] = m["curr_viewership"] - m["prev_viewership"]
    total_delta = m["delta_viewership"].sum()
    m["delta_share"] = np.where(total_delta != 0, m["delta_viewership"] / total_delta, np.nan)
    m["wow_pct"] = np.where(
        m["prev_viewership"] != 0,
        (m["curr_viewership"] - m["prev_viewership"]) / m["prev_viewership"] * 100,
        np.nan
    )
    return m.sort_values("delta_viewership", ascending=False).reset_index(drop=True)


def build_summary_text(curr, prev):
    """
    ë¦¬ë”ìš© ì¸ì‚¬ì´íŠ¸í˜• ìš”ì•½ 3~4ì¤„:
    1) ì „ì²´ íë¦„(What) + ì£¼ë„ í”Œë«í¼(Where)
    2) í”Œë«í¼ íš¨ìœ¨/ë³¼ë¥¨ ê´€ì (Where, Why)
    3) Top ìŠ¤íŠ¸ë¦¬ë¨¸ êµ¬ì¡°(Who)
    4) ì†Œë¹„ í˜•íƒœ í•´ì„(So what) - ì¹´í…Œê³ ë¦¬ í‰ê·  vs ê°€ì¤‘ í‰ê· 
    """
    lines = []

    # -------------------------
    # 0) ì•ˆì „ ì¥ì¹˜
    # -------------------------
    curr_k = curr.get("kpis", {})
    curr_pf = curr.get("platform_df", pd.DataFrame()).copy()
    curr_ex = curr.get("extra", {})

    prev_k = prev.get("kpis", {}) if prev else {}
    prev_pf = prev.get("platform_df", pd.DataFrame()).copy() if prev else None

    # -------------------------
    # 1) ì „ì²´ ë·°ì–´ì‹­ WoW + ì¦ê°€/ê°ì†Œ ì£¼ë„ í”Œë«í¼
    # -------------------------
    curr_v = curr_k.get("ì´ ë·°ì–´ì‹­", np.nan)
    prev_v = prev_k.get("ì´ ë·°ì–´ì‹­", np.nan) if prev else None
    wow_v = pct_change(curr_v, prev_v) if prev else None

    if wow_v is None:
        lines.append("â€¢ ì „ì²´ ë·°ì–´ì‹­: ì „ì£¼ ë°ì´í„°ê°€ ì—†ì–´ WoW ê³„ì‚° ë¶ˆê°€ (N/A)")
    else:
        # ì¦ê°€/ê°ì†Œ ê¸°ì—¬ í”Œë«í¼
        inc = platform_wow_increment(curr_pf, prev_pf) if prev_pf is not None else None
        if inc is not None and len(inc) > 0:
            lead_platform = inc.iloc[0]["í”Œë«í¼"]
            lead_share = inc.iloc[0]["delta_share"]
            # ë¬¸ì¥ í†¤
            if wow_v < 0:
                tone = "ê°ì†Œí–ˆìœ¼ë©°"
            elif wow_v > 0:
                tone = "ì¦ê°€í–ˆìœ¼ë©°"
            else:
                tone = "ë³€í™”ê°€ ê±°ì˜ ì—†ì—ˆìœ¼ë©°"

            if lead_platform and not pd.isna(lead_share):
                lines.append(
                    f"â€¢ ì „ì²´ ë·°ì–´ì‹­ì€ ì „ì£¼ ëŒ€ë¹„ {fmt_pct(wow_v)}ë¡œ {tone} "
                    f"{lead_platform}ì´(ê°€) ë³€í™”ë¶„ì˜ {lead_share*100:.0f}%ë¥¼ ì£¼ë„í•¨."
                )
            else:
                lines.append(f"â€¢ ì „ì²´ ë·°ì–´ì‹­ì€ ì „ì£¼ ëŒ€ë¹„ {fmt_pct(wow_v)}.")
        else:
            lines.append(f"â€¢ ì „ì²´ ë·°ì–´ì‹­ì€ ì „ì£¼ ëŒ€ë¹„ {fmt_pct(wow_v)}.")

    # -------------------------
    # 2) í”Œë«í¼ êµ¬ì¡°(ë³¼ë¥¨ vs íš¨ìœ¨) í•´ì„ í•œ ì¤„
    # - ë·°ì–´ì‹­(ë³¼ë¥¨) 1ìœ„ í”Œë«í¼
    # - í‰ê· ì‹œì²­ì(íš¨ìœ¨) 1ìœ„ í”Œë«í¼
    # -------------------------
    if len(curr_pf) >= 1 and ("ë·°ì–´ì‹­" in curr_pf.columns) and ("í‰ê· ì‹œì²­ì" in curr_pf.columns):
        pf_sorted_v = curr_pf.sort_values("ë·°ì–´ì‹­", ascending=False)
        pf_sorted_eff = curr_pf.sort_values("í‰ê· ì‹œì²­ì", ascending=False)

        vol_leader = pf_sorted_v.iloc[0]["í”Œë«í¼"]
        eff_leader = pf_sorted_eff.iloc[0]["í”Œë«í¼"]

        if vol_leader == eff_leader:
            lines.append(f"â€¢ í”Œë«í¼ êµ¬ì¡°: {vol_leader}ì´(ê°€) ë³¼ë¥¨(ë·°ì–´ì‹­)ê³¼ íš¨ìœ¨(í‰ê·  ì‹œì²­ì) ëª¨ë‘ ìš°ì„¸í•œ êµ¬ê°„.")
        else:
            lines.append(
                f"â€¢ í”Œë«í¼ êµ¬ì¡°: ë³¼ë¥¨(ë·°ì–´ì‹­)ì€ {vol_leader} ì¤‘ì‹¬, "
                f"íš¨ìœ¨(í‰ê·  ì‹œì²­ì)ì€ {eff_leader} ìš°ì„¸ â†’ ìœ ì… vs íš¨ìœ¨ì´ ë¶„ë¦¬ëœ êµ¬ì¡°."
            )

    # -------------------------
    # 3) Top ìŠ¤íŠ¸ë¦¬ë¨¸ êµ¬ì¡°(ì§‘ì¤‘ë„/ì˜ì¡´ë„) í•´ì„
    # -------------------------
    ts = curr_ex.get("top_streamer_name")
    ts_share = curr_ex.get("top_streamer_share")

    if ts and ts_share is not None and not pd.isna(ts_share):
        # ì˜ì¡´ë„ í•´ì„(ì„ê³„ê°’ì€ ìš´ì˜í•˜ë©´ì„œ ì¡°ì • ê°€ëŠ¥)
        if ts_share >= 0.15:
            dep = "ìƒìœ„ ìŠ¤íŠ¸ë¦¬ë¨¸ ì˜ì¡´ë„ê°€ ë†’ì€ í¸"
        elif ts_share >= 0.10:
            dep = "ìƒìœ„ ìŠ¤íŠ¸ë¦¬ë¨¸ ì¤‘ì‹¬ êµ¬ì¡°ê°€ ìœ ì§€"
        else:
            dep = "ìƒìœ„ ìŠ¤íŠ¸ë¦¬ë¨¸ ì§‘ì¤‘ë„ëŠ” ê³¼ë„í•˜ì§€ ì•ŠìŒ"

        lines.append(f"â€¢ Top ìŠ¤íŠ¸ë¦¬ë¨¸ {ts}ê°€ ì „ì²´ ë·°ì–´ì‹­ì˜ {ts_share*100:.0f}%ë¥¼ ê¸°ì—¬ â†’ {dep}.")

    # -------------------------
    # 4) ì†Œë¹„ í˜•íƒœ í•´ì„(ì¹´í…Œê³ ë¦¬ í‰ê·  vs ê°€ì¤‘ í‰ê· )
    # -------------------------
    cat_avg = curr_k.get("í‰ê·  ì‹œì²­ì(ì¹´í…Œê³ ë¦¬)", np.nan)
    w_avg = curr_k.get("ê°€ì¤‘ í‰ê·  ì‹œì²­ì(ë·°ì–´ì‹­/ì‹œê°„)", np.nan)

    if (not pd.isna(cat_avg)) and (not pd.isna(w_avg)) and cat_avg > 0:
        ratio = w_avg / cat_avg  # ì‘ì„ìˆ˜ë¡ 'ê´€ì „í˜•/ë¶„ì‚°' í•´ì„
        # ê²½í—˜ì ìœ¼ë¡œ ì„ê³„ê°’ ì¡°ì • ì¶”ì²œ. ìš°ì„  í•©ë¦¬ì  ë””í´íŠ¸:
        if ratio < 0.20:
            insight = "ì¹´í…Œê³ ë¦¬ í‰ê·  ëŒ€ë¹„ ê°€ì¤‘ í‰ê·  ê²©ì°¨ê°€ ì»¤ ê´€ì „í˜• ì†Œë¹„(ë¶„ì‚° ì‹œì²­) ë¹„ì¤‘ì´ ë†’ì€ ì£¼ê°„ìœ¼ë¡œ í•´ì„."
        elif ratio < 0.35:
            insight = "ì¹´í…Œê³ ë¦¬ í‰ê·  ëŒ€ë¹„ ê°€ì¤‘ í‰ê·  ê²©ì°¨ê°€ ì¡´ì¬ â†’ ë¶„ì‚° ì‹œì²­ ì„±ê²©ì´ ìš°ì„¸í•˜ë‚˜ í•µì‹¬ êµ¬ê°„ë„ ìœ ì§€."
        else:
            insight = "ê°€ì¤‘ í‰ê· ì´ ì¹´í…Œê³ ë¦¬ í‰ê· ì— ê·¼ì ‘ â†’ íŠ¹ì • êµ¬ê°„ ì§‘ì¤‘/ì¶©ì„± ì‹œì²­ ì„±ê²©ì´ ê°•í™”ëœ íë¦„."

        lines.append(f"â€¢ ì†Œë¹„ í˜•íƒœ: {insight}")

    return lines

# -----------------------------
# Recommendation (ìº í˜ì¸ ëª©ì  -> í›„ë³´í’€)
# -----------------------------
PURPOSES = {
    "ëŒ€í˜• ì—…ë°ì´íŠ¸/ì‡¼ì¼€ì´ìŠ¤(íŒŒê¸‰ë ¥ ìš°ì„ )": {
        "weights": {"power": 0.55, "eff": 0.25, "stability": 0.20},
        "desc": "ìµœëŒ€/í‰ê·  ì‹œì²­ìì™€ ì´ ê¸°ì—¬(ë·°ì–´ì‹­) ì¤‘ì‹¬. í° ë¬´ëŒ€ì—ì„œ í™•ì‹¤í•œ ì¹´ë“œ."
    },
    "íš¨ìœ¨ ì¤‘ì‹¬(ì˜ˆì‚°/ì‹œê°„ ì œí•œ)": {
        "weights": {"power": 0.25, "eff": 0.55, "stability": 0.20},
        "desc": "ë°©ì†¡ì‹œê°„ ëŒ€ë¹„ ì„±ê³¼(ë·°ì–´ì‹­/ì‹œê°„) ì¤‘ì‹¬. ë¹„ìš©/ì‹œê°„ ëŒ€ë¹„ íš¨ìœ¨ ìµœì í™”."
    },
    "ì‹ ê·œ/ì¤‘ê²¬ ë°œêµ´(ì„±ì¥/ê¸°íšŒ)": {
        "weights": {"power": 0.25, "eff": 0.35, "stability": 0.40},
        "desc": "ì „ì£¼ ëŒ€ë¹„ ê°œì„ /ì•ˆì •(ì¶”ì„¸) ë¹„ì¤‘ì„ ë†’ì—¬, ë‹¤ìŒ ë‹¬ ì„±ì¥ í›„ë³´ë¥¼ ì°¾ìŒ."
    },
    "ë¦¬ìŠ¤í¬ ë‚®ì€ ìš´ì˜í˜•(ì•ˆì •/ì§€ì†)": {
        "weights": {"power": 0.25, "eff": 0.25, "stability": 0.50},
        "desc": "ì „ì£¼ ëŒ€ë¹„ í•˜ë½ ë¦¬ìŠ¤í¬ê°€ ë‚®ê³  ì„±ê³¼ê°€ ìœ ì§€ë˜ëŠ” ìŠ¤íŠ¸ë¦¬ë¨¸ ì¤‘ì‹¬."
    },
}

def compute_streamer_features(sr_df: pd.DataFrame) -> pd.DataFrame:
    """ì£¼ê°„(ìŠ¤ëƒ…ìƒ·) ìŠ¤íŠ¸ë¦¬ë¨¸ ë‹¨ìœ„ í”¼ì²˜ ìƒì„±"""
    sr = normalize_streamer_rank(sr_df)

    g = (
        sr.groupby(["í”Œë«í¼", "ìŠ¤íŠ¸ë¦¬ë¨¸"], as_index=False)
          .agg(
              ë°©ì†¡ì‹œê°„=("ë°©ì†¡ì‹œê°„", "sum"),
              í‰ê· ì‹œì²­ì=("í‰ê· ì‹œì²­ì", "mean"),
              ë·°ì–´ì‹­=("ë·°ì–´ì‹­", "sum"),
              ìµœê³ ì‹œì²­ì=("ìµœê³ ì‹œì²­ì", "max") if "ìµœê³ ì‹œì²­ì" in sr.columns else ("í‰ê· ì‹œì²­ì", "max"),
          )
    )

    total_viewership = g["ë·°ì–´ì‹­"].sum() if g["ë·°ì–´ì‹­"].notna().any() else 0.0
    g["ê¸°ì—¬ìœ¨"] = np.where(total_viewership > 0, g["ë·°ì–´ì‹­"] / total_viewership, np.nan)

    # íš¨ìœ¨(ì‹œê°„ ëŒ€ë¹„ ì„±ê³¼)
    g["íš¨ìœ¨(ë·°ì–´ì‹­/ì‹œê°„)"] = np.where(g["ë°©ì†¡ì‹œê°„"] > 0, g["ë·°ì–´ì‹­"] / g["ë°©ì†¡ì‹œê°„"], np.nan)

    # í”¼í¬ ì˜ì¡´ë„(ì´ë²¤íŠ¸í˜•/ìŠ¤íŒŒì´í¬ ì„±í–¥ íƒì§€ìš©)
    g["í”¼í¬ë¹„ìœ¨(ìµœê³ /í‰ê· )"] = np.where(
        (g["í‰ê· ì‹œì²­ì"] > 0) & g["ìµœê³ ì‹œì²­ì"].notna(),
        g["ìµœê³ ì‹œì²­ì"] / g["í‰ê· ì‹œì²­ì"],
        np.nan
    )

    # í˜„ì¬ ë„ˆ ì½”ë“œì˜ ë¶„ë¥˜ ë¡œì§ ì¬ì‚¬ìš©(ìƒëŒ€ ë­í¬ ê¸°ë°˜)
    g["ë°©ì†¡ì‹œê°„_rank"] = g["ë°©ì†¡ì‹œê°„"].rank(pct=True, ascending=False)
    g["í‰ê· ì‹œì²­ì_rank"] = g["í‰ê· ì‹œì²­ì"].rank(pct=True, ascending=False)

    def classify(row):
        if row["ë°©ì†¡ì‹œê°„_rank"] <= 0.25 and row["í‰ê· ì‹œì²­ì_rank"] > 0.5:
            return "ì‹œê°„í˜•"
        elif row["ë°©ì†¡ì‹œê°„_rank"] > 0.5 and row["í‰ê· ì‹œì²­ì_rank"] <= 0.25:
            return "íŒŒì›Œí˜•"
        else:
            return "ë°¸ëŸ°ìŠ¤í˜•"

    g["ê¸°ì—¬ íƒ€ì…"] = g.apply(classify, axis=1)

    return g


def attach_prev_wow(curr_feat: pd.DataFrame, prev_feat: pd.DataFrame | None) -> pd.DataFrame:
    """ì „ì£¼ í”¼ì²˜ê°€ ìˆìœ¼ë©´ WoW(ë·°ì–´ì‹­/í‰ê· ì‹œì²­ì) ê³„ì‚°í•´ì„œ ì•ˆì •ì„± ì‹œê·¸ë„ë¡œ ì‚¬ìš©"""
    out = curr_feat.copy()
    if prev_feat is None or len(prev_feat) == 0:
        out["ë·°ì–´ì‹­_WoW(%)"] = np.nan
        out["í‰ê· ì‹œì²­ì_WoW(%)"] = np.nan
        return out

    a = out.rename(columns={"ë·°ì–´ì‹­": "curr_viewership", "í‰ê· ì‹œì²­ì": "curr_avg"})
    b = prev_feat[["í”Œë«í¼", "ìŠ¤íŠ¸ë¦¬ë¨¸", "ë·°ì–´ì‹­", "í‰ê· ì‹œì²­ì"]].rename(
        columns={"ë·°ì–´ì‹­": "prev_viewership", "í‰ê· ì‹œì²­ì": "prev_avg"}
    )

    m = a.merge(b, on=["í”Œë«í¼", "ìŠ¤íŠ¸ë¦¬ë¨¸"], how="left")
    m["ë·°ì–´ì‹­_WoW(%)"] = np.where(
        (m["prev_viewership"].notna()) & (m["prev_viewership"] > 0),
        (m["curr_viewership"] - m["prev_viewership"]) / m["prev_viewership"] * 100,
        np.nan
    )
    m["í‰ê· ì‹œì²­ì_WoW(%)"] = np.where(
        (m["prev_avg"].notna()) & (m["prev_avg"] > 0),
        (m["curr_avg"] - m["prev_avg"]) / m["prev_avg"] * 100,
        np.nan
    )

    # ì›ë˜ ì»¬ëŸ¼ëª… ë³µêµ¬
    m = m.rename(columns={"curr_viewership": "ë·°ì–´ì‹­", "curr_avg": "í‰ê· ì‹œì²­ì"})
    return m


def zscore(s: pd.Series) -> pd.Series:
    s = s.astype(float)
    mu = np.nanmean(s)
    sd = np.nanstd(s)
    if sd == 0 or np.isnan(sd):
        return pd.Series([0.0] * len(s), index=s.index)
    return (s - mu) / sd


def recommend_streamers(curr_feat: pd.DataFrame, purpose_key: str, top_n: int = 20) -> pd.DataFrame:
    """ìº í˜ì¸ ëª©ì ë³„ ì¶”ì²œ ìŠ¤ì½”ì–´ë§ + ì¶”ì²œ ì‚¬ìœ  ìƒì„±"""
    cfg = PURPOSES[purpose_key]
    w = cfg["weights"]

    df = curr_feat.copy()

    # --- score components ---
    # power: í‰ê· ì‹œì²­ì + ê¸°ì—¬ìœ¨ + (ì˜µì…˜) ìµœê³ ì‹œì²­ì
    df["_power"] = (
        0.55 * zscore(df["í‰ê· ì‹œì²­ì"]) +
        0.30 * zscore(df["ê¸°ì—¬ìœ¨"].fillna(0)) +
        0.15 * zscore(df["ìµœê³ ì‹œì²­ì"].fillna(df["í‰ê· ì‹œì²­ì"]))
    )

    # efficiency: ë·°ì–´ì‹­/ì‹œê°„
    df["_eff"] = zscore(df["íš¨ìœ¨(ë·°ì–´ì‹­/ì‹œê°„)"])

    # stability: ì „ì£¼ ëŒ€ë¹„ ë³€í™”ê°€ ê·¹ë‹¨ì ì´ì§€ ì•Šê³ (ë³€ë™ ë‚®ìŒ), ìœ ì§€/ìƒìŠ¹ì´ë©´ ê°€ì 
    # ì „ì£¼ ë°ì´í„° ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ë‘ê³ , ëª©ì  ê°€ì¤‘ì¹˜ê°€ ìˆì–´ë„ ì˜í–¥ì´ í¬ì§€ ì•Šê²Œ ì„¤ê³„
    wow = df["ë·°ì–´ì‹­_WoW(%)"].copy()
    df["_stability"] = np.where(wow.isna(), 0.0, -np.abs(zscore(wow)) + 0.3 * zscore(wow))

    df["ì¶”ì²œì ìˆ˜"] = (
        w["power"] * df["_power"] +
        w["eff"] * df["_eff"] +
        w["stability"] * df["_stability"]
    )

    # --- explanation (ì¶”ì²œ ì‚¬ìœ ) ---
    # í¼ì„¼íƒ€ì¼ ê¸°ë°˜ìœ¼ë¡œ 'ì‚¬ìœ  ë¬¸ì¥'ì„ ë§Œë“¤ë©´ UXì—ì„œ ì„¤ë“ë ¥ì´ ì¢‹ì•„ì§
    df["eff_pct"] = df["íš¨ìœ¨(ë·°ì–´ì‹­/ì‹œê°„)"].rank(pct=True) * 100
    df["power_pct"] = df["í‰ê· ì‹œì²­ì"].rank(pct=True) * 100
    df["share_pct"] = df["ê¸°ì—¬ìœ¨"].rank(pct=True) * 100

    def build_reason(r):
        reasons = []
        # ëª©ì ë³„ë¡œ ë³´ì—¬ì£¼ëŠ” í¬ì¸íŠ¸ë¥¼ ë‹¤ë¥´ê²Œ
        if w["power"] >= w["eff"]:
            reasons.append(f"í‰ê·  ì‹œì²­ì ìƒìœ„ {100 - int(r['power_pct']):d}%")
            reasons.append(f"ê¸°ì—¬ìœ¨ ìƒìœ„ {100 - int(r['share_pct']):d}%")
        else:
            reasons.append(f"íš¨ìœ¨(ë·°ì–´ì‹­/ì‹œê°„) ìƒìœ„ {100 - int(r['eff_pct']):d}%")
            reasons.append(f"ë°©ì†¡ì‹œê°„ {r['ë°©ì†¡ì‹œê°„']:.1f}h ëŒ€ë¹„ ë·°ì–´ì‹­ {r['ë·°ì–´ì‹­']:,.0f}")

        # í”¼í¬ ì„±í–¥(ì´ë²¤íŠ¸í˜•) ë³´ì¡° ì„¤ëª…
        if pd.notna(r["í”¼í¬ë¹„ìœ¨(ìµœê³ /í‰ê· )"]) and r["í”¼í¬ë¹„ìœ¨(ìµœê³ /í‰ê· )"] >= 2.0:
            reasons.append("í”¼í¬í˜•(ì´ë²¤íŠ¸/ìŠ¤íŒŒì´í¬ ì„±í–¥)")

        # ì „ì£¼ ì •ë³´ê°€ ìˆìœ¼ë©´ ì•ˆì •ì„±/ì¶”ì„¸ ë¬¸ì¥
        if pd.notna(r["ë·°ì–´ì‹­_WoW(%)"]):
            wow_txt = f"{r['ë·°ì–´ì‹­_WoW(%)']:+.0f}%"
            if r["ë·°ì–´ì‹­_WoW(%)"] >= 10:
                reasons.append(f"ì „ì£¼ ëŒ€ë¹„ ë·°ì–´ì‹­ ìƒìŠ¹({wow_txt})")
            elif r["ë·°ì–´ì‹­_WoW(%)"] <= -10:
                reasons.append(f"ì „ì£¼ ëŒ€ë¹„ ë·°ì–´ì‹­ í•˜ë½({wow_txt})")
            else:
                reasons.append(f"ì „ì£¼ ëŒ€ë¹„ ë·°ì–´ì‹­ ì•ˆì •({wow_txt})")

        # íƒ€ì… ë°°ì§€ ì˜ë¯¸
        reasons.append(f"ê¸°ì—¬ íƒ€ì…: {r['ê¸°ì—¬ íƒ€ì…']}")
        return " Â· ".join(reasons[:4])

    df["ì¶”ì²œ ì‚¬ìœ "] = df.apply(build_reason, axis=1)

    # ì •ë ¬ & ì¶œë ¥ ì»¬ëŸ¼
    out = df.sort_values("ì¶”ì²œì ìˆ˜", ascending=False).head(top_n).copy()
    return out[
        ["í”Œë«í¼", "ìŠ¤íŠ¸ë¦¬ë¨¸", "ì¶”ì²œì ìˆ˜", "ë·°ì–´ì‹­", "ê¸°ì—¬ìœ¨", "ë°©ì†¡ì‹œê°„", "í‰ê· ì‹œì²­ì", "íš¨ìœ¨(ë·°ì–´ì‹­/ì‹œê°„)", "ê¸°ì—¬ íƒ€ì…", "ì¶”ì²œ ì‚¬ìœ "]
    ]


# -----------------------------
# UI helpers
# -----------------------------
def bar_chart(df, x, y, title):
    return (
        alt.Chart(df)
        .mark_bar()
        .encode(
            x=alt.X(
                f"{x}:N",
                sort="-y",
                title="í”Œë«í¼",
                axis=alt.Axis(labelAngle=0, labelPadding=8, titlePadding=12, labelFontSize=12, titleFontSize=12),
            ),
            y=alt.Y(
                f"{y}:Q",
                title=None,
                axis=alt.Axis(labelFontSize=11),
            ),
            color=alt.Color(
                f"{x}:N",
                scale=alt.Scale(domain=list(PLATFORM_COLORS.keys()), range=list(PLATFORM_COLORS.values())),
                legend=None
            ),
            tooltip=[x, y]
        )
        .properties(
            height=260,
            title=alt.TitleParams(text=title, anchor="start", fontSize=16, offset=10),
        )
        .configure_view(strokeWidth=0)
        .configure_axis(grid=True)
        .configure_title(fontSize=16)
    )


def platform_badge_html(p: str) -> str:
    p = str(p).strip()
    c = PLATFORM_COLORS.get(p, "#E5E7EB")
    fg = "#111827"
    return (
        f"<span style='background:{c}; color:{fg}; "
        "padding:2px 10px; border-radius:999px; font-weight:700; "
        "font-size:12px; white-space:nowrap; display:inline-flex; align-items:center; line-height:1.4;'>"
        f"{p}</span>"
    )


def type_badge_html(t: str) -> str:
    t = str(t).strip()
    c = TYPE_BADGE.get(t, {"bg": "#E5E7EB", "fg": "#111827"})
    return (
        f"<span style='background:{c['bg']}; color:{c['fg']}; "
        "padding:2px 10px; border-radius:999px; font-weight:700; "
        "font-size:12px; white-space:nowrap; display:inline-flex; align-items:center; line-height:1.4;'>"
        f"{t}</span>"
    )


# -----------------------------
# UI
# -----------------------------
# -----------------------------
# Sidebar (ê°€ì¥ ìœ„)
# -----------------------------
with st.sidebar:
    st.header("ê²Œì„ ì„ íƒ")

    game = st.selectbox(
        "ê²Œì„",
        ["ARCRaiders", "THEFINALS"]
    )

    data_dir = f"data/{game}"


# -----------------------------
# Main UI
# -----------------------------
st.title(f"{game} ì¸í”Œë£¨ì–¸ì„œ ì „ëµ ëŒ€ì‹œë³´ë“œ")

st.sidebar.markdown("### DEBUG")
st.sidebar.write(
    "GIT_SHA:",
    subprocess.check_output(["git", "rev-parse", "--short", "HEAD"]).decode().strip()
)

data = load_latest_prev_streamer_softcon_and_cat(data_dir)
st.sidebar.markdown("### CAT DEBUG")
st.sidebar.write("CAT_FILE:", data["cat_filename"])
st.sidebar.write("CAT_MAX_DATE:", pd.to_datetime(data["cat_current"].get("ë‚ ì§œ"), errors="coerce").max())

if data is None:
    st.warning("data í´ë”ì—ì„œ í•„ìš”í•œ CSVë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n"
               "- ìŠ¤íŠ¸ë¦¬ë¨¸_ë­í‚¹_YYYYMMDD*.csv (ìµœì†Œ 1ê°œ)\n"
               "- ì¹´í…Œê³ ë¦¬_í”Œë«í¼ë³„_í†µê³„*.csv (ìµœì†Œ 1ê°œ)")
    st.stop()

# ì¹´í…Œê³ ë¦¬ í†µê³„(ëˆ„ì  1íŒŒì¼)ì—ì„œ ìµœì‹  ì£¼/ì „ì£¼ ë¶„ë¦¬
curr_week, prev_week, cs_curr, cs_prev = split_curr_prev_weeks_from_cat_stats(data["cat_current"])
if curr_week is None:
    st.warning("ì¹´í…Œê³ ë¦¬_í”Œë«í¼ë³„_í†µê³„ì—ì„œ ë‚ ì§œë¥¼ ì½ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. 'ë‚ ì§œ' ì»¬ëŸ¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# ìŠ¤íŠ¸ë¦¬ë¨¸ ìµœì‹ /ì „ì£¼ (íŒŒì¼ëª… ì›”ìš”ì¼ ê¸°ì¤€ìœ¼ë¡œ ë§ì¶˜ë‹¤ê³  í–ˆìœ¼ë‹ˆ ëŒ€ì²´ë¡œ ì •í•©)
sr_latest = data["streamer_latest"]
sr_prev = data["streamer_prev"]

# ìµœì‹  ì£¼ ê³„ì‚°
curr_kpis, curr_platform_df, curr_top10, curr_all_streamers, curr_extra = compute_overview_metrics(sr_latest, cs_curr)

curr_pack = {
    "kpis": curr_kpis,
    "platform_df": curr_platform_df,
    "top10": curr_top10,
    "all_streamers": curr_all_streamers,
    "extra": curr_extra
}

prev_pack = None
if sr_prev is not None and prev_week is not None and len(cs_prev) > 0:
    prev_kpis, prev_platform_df, prev_top10, prev_all_streamers, prev_extra = compute_overview_metrics(sr_prev, cs_prev)
    prev_pack = {"kpis": prev_kpis, "platform_df": prev_platform_df, "top10": prev_top10, "extra": prev_extra}


# âœ… ì£¼ê°„ ìŠ¤ëƒ…ìƒ· ë¼ë²¨: ìŠ¤íŠ¸ë¦¬ë¨¸/ì†Œí”„íŠ¸ì½˜ íŒŒì¼ ê¸°ì¤€
wk_latest = data.get("streamer_latest_date") or data.get("softcon_latest_date")
wk_prev   = data.get("streamer_prev_date")   or data.get("softcon_prev_date")

cols = st.columns(2)
with cols[0]:
    st.caption(f"ì£¼ê°„ ìŠ¤ëƒ…ìƒ·(íŒŒì¼ ê¸°ì¤€): {wk_latest if wk_latest is not None else 'N/A'}")
with cols[1]:
    st.caption(f"ì „ì£¼ ìŠ¤ëƒ…ìƒ·(íŒŒì¼ ê¸°ì¤€): {wk_prev if wk_prev is not None else 'ì—†ìŒ'}")

# ì£¼ê°„ ìš”ì•½
st.markdown("### ì£¼ê°„ ìš”ì•½")
summary_lines = build_summary_text(curr_pack, prev_pack)
for line in summary_lines:
    st.write(line)

# KPI
st.markdown("### KPI")
k1, k2, k3, k4 = st.columns(4)

with k1:
    st.markdown(
        f"""
<div>
  <div style="font-size:13px;color:#6b7280;">ì´ ë·°ì–´ì‹­</div>
  <div style="font-size:28px;font-weight:800;">
    {kpi_with_wow(
        curr_kpis["ì´ ë·°ì–´ì‹­"],
        prev_pack["kpis"]["ì´ ë·°ì–´ì‹­"] if prev_pack else None,
        decimals=0
    )}
  </div>
</div>
""",
        unsafe_allow_html=True
    )

with k2:
    st.markdown(
        f"""
<div>
  <div style="font-size:13px;color:#6b7280;">í‰ê·  ì‹œì²­ì(ì¹´í…Œê³ ë¦¬)</div>
  <div style="font-size:28px;font-weight:800;">
    {kpi_with_wow(
        curr_kpis["í‰ê·  ì‹œì²­ì(ì¹´í…Œê³ ë¦¬)"],
        prev_pack["kpis"]["í‰ê·  ì‹œì²­ì(ì¹´í…Œê³ ë¦¬)"] if prev_pack else None,
        decimals=0
    )}
  </div>
</div>
""",
        unsafe_allow_html=True
    )

with k3:
    st.markdown(
        f"""
<div>
  <div style="font-size:13px;color:#6b7280;">ì´ ë°©ì†¡ì‹œê°„</div>
  <div style="font-size:28px;font-weight:800;">
    {kpi_with_wow(
        curr_kpis["ì´ ë°©ì†¡ì‹œê°„"],
        prev_pack["kpis"]["ì´ ë°©ì†¡ì‹œê°„"] if prev_pack else None,
        decimals=0
    )}
  </div>
</div>
""",
        unsafe_allow_html=True
    )

with k4:
    st.markdown(
        f"""
<div>
  <div style="font-size:13px;color:#6b7280;">ê°€ì¤‘ í‰ê·  ì‹œì²­ì(ë·°ì–´ì‹­/ì‹œê°„)</div>
  <div style="font-size:28px;font-weight:800;">
    {kpi_with_wow(
        curr_kpis["ê°€ì¤‘ í‰ê·  ì‹œì²­ì(ë·°ì–´ì‹­/ì‹œê°„)"],
        prev_pack["kpis"]["ê°€ì¤‘ í‰ê·  ì‹œì²­ì(ë·°ì–´ì‹­/ì‹œê°„)"] if prev_pack else None,
        decimals=1
    )}
  </div>
</div>
""",
        unsafe_allow_html=True
    )


# KPI -> í”Œë«í¼ ë¹„êµ ì—¬ë°±
st.markdown("<div style='height:24px;'></div>", unsafe_allow_html=True)

# í”Œë«í¼ ë¹„êµ ì°¨íŠ¸
st.markdown("### í”Œë«í¼ ë¹„êµ")
pf = curr_platform_df.copy().sort_values("ë·°ì–´ì‹­", ascending=False)
c1, c2, c3 = st.columns(3)
c1.altair_chart(bar_chart(pf, "í”Œë«í¼", "ë°©ì†¡ì‹œê°„", "ë°©ì†¡ì‹œê°„"), use_container_width=True)
c2.altair_chart(bar_chart(pf, "í”Œë«í¼", "í‰ê· ì‹œì²­ì", "í‰ê·  ì‹œì²­ì(ë·°ì–´ì‹­/ë°©ì†¡ì‹œê°„)"), use_container_width=True)
c3.altair_chart(bar_chart(pf, "í”Œë«í¼", "ë·°ì–´ì‹­", "ë·°ì–´ì‹­"), use_container_width=True)

# -----------------------------
# Top ìŠ¤íŠ¸ë¦¬ë¨¸ í…Œì´ë¸” (ì •ë ¬ í† ê¸€ + ë°°ì§€)
# -----------------------------
st.markdown("### Top ìŠ¤íŠ¸ë¦¬ë¨¸ (Top 10)")

sort_key = st.radio(
    "ì •ë ¬ ê¸°ì¤€",
    options=["ë·°ì–´ì‹­", "í‰ê· ì‹œì²­ì"],  # ğŸ‘ˆ ë””í´íŠ¸ê°€ ì•ì—
    index=0,                            # ğŸ‘ˆ ì²« ë²ˆì§¸ = ë·°ì–´ì‹­
    horizontal=True,
    key="top_streamer_sort"
)


sort_col = "í‰ê· ì‹œì²­ì" if sort_key == "í‰ê· ì‹œì²­ì" else "ë·°ì–´ì‹­"
st.caption(f"â€» ì •ë ¬ ê¸°ì¤€: {sort_key}(ë‚´ë¦¼ì°¨ìˆœ)")

# ---------------------------
# ë°°ì§€ ì„¤ì • (ë¬¸êµ¬/ê¸°ì¤€)  âœ… ì „ì²´ í’€ ê¸°ì¤€
# ---------------------------
BADGE_TEXT = "íš¨ìœ¨ ìƒìœ„"       # ì¶”ì²œ: "íš¨ìœ¨ ìƒìœ„" / "í•µì‹¬ í›„ë³´" / "ê³ íš¨ìœ¨ ìš´ì˜"
LOW_HOURS_PCTL = 0.20          # ë°©ì†¡ì‹œê°„ í•˜ìœ„ 20% = 'ìƒëŒ€ì ìœ¼ë¡œ ì§§ì€ ë°©ì†¡'
HIGH_AVG_PCTL = 0.80           # í‰ê· ì‹œì²­ì ìƒìœ„ 20% = 'ì˜í–¥ë ¥ ìƒìœ„'

def highlight_badge_html(text: str) -> str:
    return f"""
    <span style="
        display:inline-flex;
        align-items:center;
        margin-left:8px;
        padding:2px 8px;
        border-radius:999px;
        font-size:11px;
        font-weight:800;
        background:#ECFDF5;
        color:#047857;
        border:1px solid #A7F3D0;
        line-height:1.4;
        white-space:nowrap;
    ">{text}</span>
    """

# âœ… ëª¨ì§‘ë‹¨: Top10(ë·°ì–´ì‹­) ë§ê³  ì „ì²´ í’€ì—ì„œ ë½‘ì•„ì•¼ "ì§§ë°© ê³ ì˜í–¥"ì´ ë“¤ì–´ì˜¨ë‹¤
table = curr_all_streamers.copy()
table["ê¸°ì—¬ìœ¨(%)"] = (table["ê¸°ì—¬ìœ¨"] * 100).round(0)

# âœ… ë°°ì§€ ì„ê³„ê°’ë„ ì „ì²´ í’€ ê¸°ì¤€
pool = curr_all_streamers.copy()
hours_threshold = pool["ë°©ì†¡ì‹œê°„"].quantile(LOW_HOURS_PCTL) if pool["ë°©ì†¡ì‹œê°„"].notna().any() else None
avg_threshold = pool["í‰ê· ì‹œì²­ì"].quantile(HIGH_AVG_PCTL) if pool["í‰ê· ì‹œì²­ì"].notna().any() else None

def is_high_eff(row) -> bool:
    if (hours_threshold is None) or (avg_threshold is None):
        return False
    return (
        pd.notna(row["ë°©ì†¡ì‹œê°„"]) and pd.notna(row["í‰ê· ì‹œì²­ì"]) and
        (row["ë°©ì†¡ì‹œê°„"] <= hours_threshold) and
        (row["í‰ê· ì‹œì²­ì"] >= avg_threshold)
    )

table["_high_eff"] = table.apply(is_high_eff, axis=1)

# âœ… ì •ë ¬ ì ìš© í›„ Top10 ì¶”ì¶œ (ì—¬ê¸°ì„œ ë“œë””ì–´ "í‰ê· ì‹œì²­ì Top10"ì´ ê°€ëŠ¥í•´ì§)
secondary = "ë·°ì–´ì‹­" if sort_col == "í‰ê· ì‹œì²­ì" else "í‰ê· ì‹œì²­ì"
table = table.sort_values(
    by=[sort_col, secondary, "ë°©ì†¡ì‹œê°„"],
    ascending=[False, False, False],
    na_position="last"
).head(10)

# ì›í•˜ëŠ” ì»¬ëŸ¼ ìˆœì„œ
table = table[["í”Œë«í¼", "ìŠ¤íŠ¸ë¦¬ë¨¸", "ë·°ì–´ì‹­", "ê¸°ì—¬ìœ¨(%)", "ë°©ì†¡ì‹œê°„", "í‰ê· ì‹œì²­ì", "ê¸°ì—¬ íƒ€ì…", "_high_eff"]].copy()

# í‘œì‹œìš© í¬ë§·
disp = table.copy()
disp["í”Œë«í¼"] = disp["í”Œë«í¼"].map(platform_badge_html)

# ìŠ¤íŠ¸ë¦¬ë¨¸ + ë°°ì§€
disp["ìŠ¤íŠ¸ë¦¬ë¨¸"] = disp["ìŠ¤íŠ¸ë¦¬ë¨¸"].astype(str)
disp["ìŠ¤íŠ¸ë¦¬ë¨¸"] = disp.apply(
    lambda r: f'{r["ìŠ¤íŠ¸ë¦¬ë¨¸"]}{highlight_badge_html(BADGE_TEXT) if r["_high_eff"] else ""}',
    axis=1
)

disp["ë·°ì–´ì‹­"] = disp["ë·°ì–´ì‹­"].map(lambda x: f"{x:,.0f}" if pd.notna(x) else "N/A")
disp["ê¸°ì—¬ìœ¨(%)"] = disp["ê¸°ì—¬ìœ¨(%)"].map(lambda x: f"{x:.0f}" if pd.notna(x) else "N/A")
disp["ë°©ì†¡ì‹œê°„"] = disp["ë°©ì†¡ì‹œê°„"].map(lambda x: f"{x:>6.1f}" if pd.notna(x) else "N/A")
disp["í‰ê· ì‹œì²­ì"] = disp["í‰ê· ì‹œì²­ì"].map(lambda x: f"{x:>6.1f}" if pd.notna(x) else "N/A")
disp["ê¸°ì—¬ íƒ€ì…"] = disp["ê¸°ì—¬ íƒ€ì…"].map(type_badge_html)

cols = ["í”Œë«í¼", "ìŠ¤íŠ¸ë¦¬ë¨¸", "ë·°ì–´ì‹­", "ê¸°ì—¬ìœ¨(%)", "ë°©ì†¡ì‹œê°„", "í‰ê· ì‹œì²­ì", "ê¸°ì—¬ íƒ€ì…"]

rows_html = ""
for _, r in disp[cols].iterrows():
    rows_html += "<tr>" + "".join([f"<td>{r[c]}</td>" for c in cols]) + "</tr>"

# (ì„ íƒ) ë°°ì§€ ì¡°ê±´ì„ ìº¡ì…˜ìœ¼ë¡œ ê°™ì´ ë³´ì—¬ì£¼ë©´ ì„¤ë“ë ¥ ì˜¬ë¼ê°
badge_caption = ""
if (hours_threshold is not None) and (avg_threshold is not None):
    badge_caption = f" Â· {BADGE_TEXT}: ë°©ì†¡ì‹œê°„ â‰¤ {hours_threshold:.1f}h(í•˜ìœ„ {int(LOW_HOURS_PCTL*100)}%) & í‰ê· ì‹œì²­ì â‰¥ {avg_threshold:.1f}(ìƒìœ„ {int((1-HIGH_AVG_PCTL)*100)}%)"

st.caption(f"â€» ë°°ì§€{badge_caption}" if badge_caption else "â€» ë°°ì§€: ê³„ì‚° ë¶ˆê°€(ë°ì´í„° ë¶€ì¡±)")

html = f"""
<style>
.table-wrap {{
  width: 100%;
  max-width: 980px;
}}

.custom-table {{
  border-collapse: collapse;
  width: 100%;
  font-size: 13px;
}}

.custom-table th, .custom-table td {{
  border: 1px solid #e5e7eb;
  padding: 10px 12px;
  vertical-align: middle;
}}

.custom-table th {{
  background: #f9fafb;
  text-align: left;
  font-weight: 800;
}}

.custom-table td:nth-child(3),
.custom-table td:nth-child(4),
.custom-table td:nth-child(5),
.custom-table td:nth-child(6) {{
  text-align: right;
}}

.custom-table td:nth-child(1),
.custom-table td:nth-child(7) {{
  text-align: center;
}}
</style>

<div class="table-wrap">
<table class="custom-table">
  <thead>
    <tr>
      {''.join([f'<th>{c}</th>' for c in cols])}
    </tr>
  </thead>
  <tbody>
    {rows_html}
  </tbody>
</table>
</div>
"""

st.markdown(html, unsafe_allow_html=True)



# ê¸°ì—¬ íƒ€ì… ì •ì˜(í‘œ ì•„ë˜, ê°„ê²© í¬í•¨)
st.markdown("#### ê¸°ì—¬ íƒ€ì… ì •ì˜")
st.markdown(
    """
<div style="display:flex; gap:16px; align-items:center; margin-top:6px; margin-bottom:12px; flex-wrap:wrap;">

  <div style="display:flex; align-items:center; gap:6px;">
    <span style="background:#C4B5FD;color:#312E81;padding:2px 10px;border-radius:999px;
                 font-weight:700;font-size:12px;line-height:1.4;display:inline-flex;align-items:center;">
      ì‹œê°„í˜•
    </span>
    <span style="font-size:12px;color:#4b5563;">
      ë°©ì†¡ì‹œê°„ ë¹„ì¤‘ì´ ë†’ì€ ê¾¸ì¤€í˜•
    </span>
  </div>

  <div style="display:flex; align-items:center; gap:6px;">
    <span style="background:#FCA5A5;color:#7F1D1D;padding:2px 10px;border-radius:999px;
                 font-weight:700;font-size:12px;line-height:1.4;display:inline-flex;align-items:center;">
      íŒŒì›Œí˜•
    </span>
    <span style="font-size:12px;color:#4b5563;">
      ì§§ì€ ë°©ì†¡ì—ë„ í‰ê·  ì‹œì²­ì ë†’ìŒ
    </span>
  </div>

  <div style="display:flex; align-items:center; gap:6px;">
    <span style="background:#D1D5DB;color:#111827;padding:2px 10px;border-radius:999px;
                 font-weight:700;font-size:12px;line-height:1.4;display:inline-flex;align-items:center;">
      ë°¸ëŸ°ìŠ¤í˜•
    </span>
    <span style="font-size:12px;color:#4b5563;">
      ì‹œê°„Â·ì‹œì²­ì ëª¨ë‘ ê³ ë¥´ê²Œ ê¸°ì—¬
    </span>
  </div>

</div>
""",
    unsafe_allow_html=True
)

# -----------------------------
# ìº í˜ì¸ ì¶”ì²œ (ë§¨ ì•„ë˜, ê¸°ë³¸ ì ‘í˜) - ë”ë³´ê¸° ì ìš©
# -----------------------------
st.markdown("<div style='height:18px;'></div>", unsafe_allow_html=True)

with st.expander("â­ìº í˜ì¸ í›„ë³´ íƒìƒ‰", expanded=False):

    # ë”ë³´ê¸° ìƒíƒœ ì €ì¥ í‚¤(ê²Œì„ë³„ë¡œ ë¶„ë¦¬í•˜ê³  ì‹¶ìœ¼ë©´ gameì„ í¬í•¨)
    more_key = f"rec_more_{game}"

    left, right = st.columns([1.1, 2.9])

    with left:
        purpose = st.selectbox("ìº í˜ì¸ ëª©ì ", list(PURPOSES.keys()), key="purpose_select_bottom")
        st.caption(PURPOSES[purpose]["desc"])

        pf_filter = st.multiselect(
            "í”Œë«í¼ í•„í„°",
            options=sorted(curr_platform_df["í”Œë«í¼"].unique().tolist()),
            default=sorted(curr_platform_df["í”Œë«í¼"].unique().tolist()),
            key="pf_filter_bottom"
        )

        type_filter = st.multiselect(
            "ê¸°ì—¬ íƒ€ì…",
            options=["ì‹œê°„í˜•", "íŒŒì›Œí˜•", "ë°¸ëŸ°ìŠ¤í˜•"],
            default=["ì‹œê°„í˜•", "íŒŒì›Œí˜•", "ë°¸ëŸ°ìŠ¤í˜•"],
            key="type_filter_bottom"
        )

        min_avg = st.number_input(
            "ìµœì†Œ í‰ê·  ì‹œì²­ì",
            min_value=0,
            value=0,
            step=10,
            key="min_avg_bottom"
        )

        # âœ… ë”ë³´ê¸° ìƒíƒœ ì´ˆê¸°í™”(ì—†ìœ¼ë©´ False)
        if more_key not in st.session_state:
            st.session_state[more_key] = False

    # âœ… (ì¤‘ìš”) ëª©ì /í•„í„°ë¥¼ ë°”ê¾¸ë©´ "ë”ë³´ê¸°"ëŠ” ìë™ìœ¼ë¡œ ì ‘íˆëŠ” ê²Œ UXê°€ ì¢‹ìŒ
    # Streamlitì€ ìœ„ì ¯ ë³€ê²½ ê°ì§€ë¥¼ ì§ì ‘ ë°›ê¸° ì–´ë µê¸° ë•Œë¬¸ì—,
    # ì¶”ì²œ ê²°ê³¼(í‚¤ íŒŒë¼ë¯¸í„°) ê¸°ë°˜ìœ¼ë¡œ í•´ì‹œë¥¼ ë§Œë“¤ì–´ ë¦¬ì…‹í•˜ëŠ” ë°©ì‹ ì‚¬ìš©
    state_sig = (purpose, tuple(pf_filter), tuple(type_filter), int(min_avg))
    sig_key = f"rec_sig_{game}"
    if st.session_state.get(sig_key) != state_sig:
        st.session_state[sig_key] = state_sig
        st.session_state[more_key] = False  # ë¦¬ì…‹

    # âœ… ì¶”ì²œ ë°ì´í„° ì†ŒìŠ¤: ì›”ê°„ ìš°ì„ , ì—†ìœ¼ë©´ ì£¼ê°„
    sr_rec = data.get("streamer_monthly_latest")
    sr_rec_prev = data.get("streamer_monthly_prev")
    using_monthly = (sr_rec is not None)

    if not using_monthly:
        sr_rec = sr_latest
        sr_rec_prev = sr_prev


    # -------------------------
    # ì¶”ì²œ ê³„ì‚°: 20ëª… ìƒì„± í›„, í™”ë©´ í‘œì‹œë§Œ 10/20 í† ê¸€
    # -------------------------
    curr_feat = compute_streamer_features(sr_rec)
    prev_feat = compute_streamer_features(sr_rec_prev) if sr_rec_prev is not None else None
    curr_feat = attach_prev_wow(curr_feat, prev_feat)

    rec_all = recommend_streamers(curr_feat, purpose_key=purpose, top_n=20)


    # í•„í„° ì ìš©
    rec_all = rec_all[rec_all["í”Œë«í¼"].isin(pf_filter)]
    rec_all = rec_all[rec_all["ê¸°ì—¬ íƒ€ì…"].isin(type_filter)]
    rec_all = rec_all[rec_all["í‰ê· ì‹œì²­ì"] >= float(min_avg)]

    # í‘œì‹œ ê°œìˆ˜ ê²°ì •
    show_n = 20 if st.session_state[more_key] else 10
    rec = rec_all.head(show_n).copy()

    with right:
        st.caption("â€» ì¶”ì²œì ìˆ˜ëŠ” ëª©ì ë³„ ê°€ì¤‘ì¹˜ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤. ì „ì£¼ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì•ˆì •ì„± í•­ëª©ì€ ì¤‘ë¦½ ì²˜ë¦¬ë©ë‹ˆë‹¤.")

        if rec_all.empty:
            st.info("ì¡°ê±´ì— ë§ëŠ” ì¶”ì²œ í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. (í•„í„°/ìµœì†Œ í‰ê·  ì‹œì²­ì ê¸°ì¤€ì„ ì™„í™”í•´ë³´ì„¸ìš”)")
        else:
            # -------------------------
            # 1) Top 3 ì¹´ë“œ (UX ì¹œí™”)
            # -------------------------
            top3 = rec_all.head(3).copy()

            def render_card(row):
                platform_badge = platform_badge_html(row["í”Œë«í¼"])
                t_badge = type_badge_html(row["ê¸°ì—¬ íƒ€ì…"])

                # ìˆ«ì í¬ë§·
                score = f"{row['ì¶”ì²œì ìˆ˜']:.2f}"
                vv = f"{row['ë·°ì–´ì‹­']:,.0f}"
                share = f"{row['ê¸°ì—¬ìœ¨']*100:.0f}%"
                hours = f"{row['ë°©ì†¡ì‹œê°„']:.1f}h"
                avg = f"{row['í‰ê· ì‹œì²­ì']:.1f}"
                eff = f"{row['íš¨ìœ¨(ë·°ì–´ì‹­/ì‹œê°„)']:,.0f}" if pd.notna(row["íš¨ìœ¨(ë·°ì–´ì‹­/ì‹œê°„)"]) else "N/A"

                reason = str(row["ì¶”ì²œ ì‚¬ìœ "])

                return f"""
                <div style="
                    border:1px solid #e5e7eb; border-radius:14px; padding:14px 14px;
                    background:#ffffff; box-shadow:0 1px 2px rgba(0,0,0,0.04);
                    height: 100%;
                ">
                <div style="display:flex; align-items:center; justify-content:space-between; gap:12px;">
                    <div style="display:flex; align-items:center; gap:8px;">
                    {platform_badge}
                    <span style="font-weight:900; font-size:16px;">{row['ìŠ¤íŠ¸ë¦¬ë¨¸']}</span>
                    </div>
                    <div style="display:flex; align-items:center; gap:8px;">
                    <span style="font-weight:900; font-size:14px;">Score {score}</span>
                    {t_badge}
                    </div>
                </div>

                <div style="margin-top:10px; color:#374151; font-size:13px; line-height:1.45;">
                    {reason}
                </div>

                <div style="margin-top:12px; display:flex; gap:10px; flex-wrap:wrap; font-size:12px; color:#4b5563;">
                    <div><b>ë·°ì–´ì‹­</b> {vv}</div>
                    <div><b>ê¸°ì—¬ìœ¨</b> {share}</div>
                    <div><b>ë°©ì†¡ì‹œê°„</b> {hours}</div>
                    <div><b>í‰ê· ì‹œì²­ì</b> {avg}</div>
                    <div><b>íš¨ìœ¨</b> {eff}</div>
                </div>
                </div>
                """

        st.markdown("#### ì¶”ì²œ Top 3")
        card_cols = st.columns(3)
        for i in range(min(3, len(top3))):
            with card_cols[i]:
                st.markdown(render_card(top3.iloc[i]), unsafe_allow_html=True)

        st.markdown("<div style='height:10px;'></div>", unsafe_allow_html=True)

        # -------------------------
        # 2) í‘œ (ê¸°ë³¸ 10ëª… / ë”ë³´ê¸° ì‹œ 20ëª…)
        # -------------------------
        show = rec.copy()
        show["í”Œë«í¼"] = show["í”Œë«í¼"].map(platform_badge_html)
        show["ê¸°ì—¬ íƒ€ì…"] = show["ê¸°ì—¬ íƒ€ì…"].map(type_badge_html)
        show["ì¶”ì²œì ìˆ˜"] = show["ì¶”ì²œì ìˆ˜"].map(lambda x: f"{x:,.2f}")
        show["ë·°ì–´ì‹­"] = show["ë·°ì–´ì‹­"].map(lambda x: f"{x:,.0f}")
        show["ê¸°ì—¬ìœ¨"] = (show["ê¸°ì—¬ìœ¨"] * 100).map(lambda x: f"{x:.0f}%")
        show["ë°©ì†¡ì‹œê°„"] = show["ë°©ì†¡ì‹œê°„"].map(lambda x: f"{x:.1f}h")
        show["í‰ê· ì‹œì²­ì"] = show["í‰ê· ì‹œì²­ì"].map(lambda x: f"{x:.1f}")
        show["íš¨ìœ¨(ë·°ì–´ì‹­/ì‹œê°„)"] = show["íš¨ìœ¨(ë·°ì–´ì‹­/ì‹œê°„)"].map(lambda x: f"{x:,.0f}")

        cols = ["í”Œë«í¼", "ìŠ¤íŠ¸ë¦¬ë¨¸", "ì¶”ì²œì ìˆ˜", "ì¶”ì²œ ì‚¬ìœ ", "ë·°ì–´ì‹­", "ê¸°ì—¬ìœ¨", "ë°©ì†¡ì‹œê°„", "í‰ê· ì‹œì²­ì", "íš¨ìœ¨(ë·°ì–´ì‹­/ì‹œê°„)", "ê¸°ì—¬ íƒ€ì…"]

        rows_html = ""
        for _, r in show[cols].iterrows():
            rows_html += "<tr>" + "".join([f"<td>{r[c]}</td>" for c in cols]) + "</tr>"

        html = f"""
        <style>
        .rec-table {{
          border-collapse: collapse;
          width: 100%;
          font-size: 13px;
        }}
        .rec-table th, .rec-table td {{
          border: 1px solid #e5e7eb;
          padding: 10px 12px;
          vertical-align: top;
        }}
        .rec-table th {{
          background: #f9fafb;
          text-align: left;
          font-weight: 800;
        }}
        .rec-table td:nth-child(3),
        .rec-table td:nth-child(5),
        .rec-table td:nth-child(6),
        .rec-table td:nth-child(7),
        .rec-table td:nth-child(8),
        .rec-table td:nth-child(9) {{
          text-align: right;
          white-space: nowrap;
        }}
        .rec-table td:nth-child(1),
        .rec-table td:nth-child(10) {{
          text-align: center;
          white-space: nowrap;
        }}
        .rec-table td:nth-child(4) {{
          color: #374151;
          line-height: 1.5;
          min-width: 280px;
        }}
        </style>

        <table class="rec-table">
          <thead>
            <tr>
              {''.join([f'<th>{c}</th>' for c in cols])}
            </tr>
          </thead>
          <tbody>
            {rows_html}
          </tbody>
        </table>
        """
        st.markdown("#### ì¶”ì²œ í›„ë³´ ë¦¬ìŠ¤íŠ¸")
        st.markdown(html, unsafe_allow_html=True)

        # -------------------------
        # 3) í‘œ ì•„ë˜ ë”ë³´ê¸°/ì ‘ê¸° ë²„íŠ¼ (ìš”ì²­ì‚¬í•­)
        # -------------------------
        st.markdown("<div style='height:8px;'></div>", unsafe_allow_html=True)

        footer_cols = st.columns([1.2, 1.2, 7.6])
        with footer_cols[0]:
            if (not st.session_state[more_key]) and (len(rec_all) > 10):
                if st.button("ë” ë³´ê¸° (+10)", key="btn_more_bottom"):
                    st.session_state[more_key] = True
                    st.rerun()
        with footer_cols[1]:
            if st.session_state[more_key]:
                if st.button("ì ‘ê¸°", key="btn_less_bottom"):
                    st.session_state[more_key] = False
                    st.rerun()

        with footer_cols[2]:
            if len(rec_all) > 10:
                shown = 20 if st.session_state[more_key] else 10
                st.caption(f"í‘œì‹œ ì¤‘: {min(shown, len(rec_all))} / {len(rec_all)}ëª…")


